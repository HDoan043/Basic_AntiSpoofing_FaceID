{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e51840",
   "metadata": {},
   "source": [
    "# **Xây dựng mô hình LivenessNet**\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f268afe",
   "metadata": {},
   "source": [
    "## **Kiến trúc mô hình**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69925156",
   "metadata": {},
   "source": [
    "### **1. Bài toán**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc8f0e",
   "metadata": {},
   "source": [
    "Bài toán **LivenessNet** yêu cầu phân biệt 1 frame ảnh trước camera là mặt thật hay là 1 kiểu proofing 2d bằng ảnh in, màn hình điện thoại hay màn hình máy tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2c384",
   "metadata": {},
   "source": [
    "**Yêu cầu:**\n",
    "* Học được các viền ảnh\n",
    "* Học được phản chiếu ánh sáng lên trên điện thoại khi proofing bằng điện thoại\n",
    "* Học được texture giấy( khi proofing bằng ảnh in )...\n",
    "* Nhẹ và chạy được theo thời gian thực\n",
    "* Thời gian huấn luyện phù hợp với tài nguyên CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae0db6",
   "metadata": {},
   "source": [
    "**Input:** Ảnh đã được resize về kích thước **64 x 64** ( sẽ tăng kích thước lên thành **128 x 128** nếu **64 x 64** không đáp ứng được yêu cầu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ed7de",
   "metadata": {},
   "source": [
    "**Output:** một giá trị xác suất trong khoảng **[0,1]** là xác suất ảnh là thật"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aed195",
   "metadata": {},
   "source": [
    "### **2. Kiến trúc mô hình**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4edac6",
   "metadata": {},
   "source": [
    "**Kiến trúc sử dụng:** Vì cần học các đặc trưng đơn giản như viền cạnh, ánh sáng phản chiếu nên ta sẽ sử dụng một mạng **CNN** đơn giản. Mạng **CNN** đơn giản đủ để phát hiện các đặc trưng thô và tinh cơ bản. Mạng được xây dựng theo kiến trúc sau:\n",
    "* **Lớp 1: Conv2D**\n",
    "    * Số filter: 32\n",
    "    * Kích thước filter: 3x3\n",
    "    * Padding cho kích thước giữ nguyên với kích thước đầu vào\n",
    "    * Hàm kích hoạt : ReLU\n",
    "    * Đầu vào: 64x64x3\n",
    "    * Đầu ra: 64x64x32\n",
    "\n",
    "* **Lớp 2: BatchNormalization**\n",
    "    * Chuẩn hóa của lớp tích chập 2D phía trước\n",
    "\n",
    "* **Lớp 3: MaxPooling2D**\n",
    "    * Kích thước cửa sổ: 2x2\n",
    "    * Đầu vào: 64x64x32\n",
    "    * Đầu ra: 32x32x32\n",
    "\n",
    "* **Lớp 4: Conv2D**\n",
    "    * Số filter: 64 ( tăng số lượng filter để học được nhiều đặc trưng hơn)\n",
    "    * Kích thước filter: 3x3\n",
    "    * Padding: \"same\" ( cho giống với kích thước đầu vào)\n",
    "    * Hàm kích hoạt: ReLU\n",
    "    * Đầu vào: 32x32x32\n",
    "    * Đầu ra: 32x32x64\n",
    "\n",
    "* **Lớp 5: BatchNormalization**\n",
    "    * Chuẩn hóa của lớp tích chập 2D phía trước\n",
    "\n",
    "* **Lớp 6: MaxPooling2D**\n",
    "    * Kích thước cửa sổ: 2x2\n",
    "    * Đầu vào: 32x32x64\n",
    "    * Đầu ra: 16x16x64\n",
    "\n",
    "* **Lớp 7: Conv2D**\n",
    "    * Số filter: 128 ( tăng số lượng filter để học được nhiều đặc trưng hơn)\n",
    "    * Kích thước filter: 3x3\n",
    "    * Padding: \"same\" ( cho giống với kích thước đầu vào)\n",
    "    * Hàm kích hoạt: ReLU\n",
    "    * Đầu vào: 16x16x64\n",
    "    * Đầu ra: 16x16x128\n",
    "\n",
    "* **Lớp 8: BatchNormalization**\n",
    "    * Chuẩn hóa của lớp tích chập 2D phía trước\n",
    "\n",
    "* **Lớp 9: MaxPooling2D**\n",
    "    * Kích thước cửa sổ: 2x2\n",
    "    * Đầu vào: 16x16x128\n",
    "    * Đầu ra: 8x8x128\n",
    "\n",
    "* **Lớp 10: Conv2D**\n",
    "    * Số filter: 128 ( tăng số lượng filter để học được nhiều đặc trưng hơn)\n",
    "    * Kích thước filter: 3x3\n",
    "    * Padding: \"same\" ( cho giống với kích thước đầu vào)\n",
    "    * Hàm kích hoạt: ReLU\n",
    "    * Đầu vào: 8x8x128\n",
    "    * Đầu ra: 8x8x128\n",
    "\n",
    "* **Lớp 11: BatchNormalization**\n",
    "    * Chuẩn hóa của lớp tích chập 2D phía trước\n",
    "\n",
    "* **Lớp 12: MaxPooling2D**\n",
    "    * Kích thước cửa sổ: 2x2\n",
    "    * Đầu vào: 8x8x128\n",
    "    * Đầu ra: 4x4x128\n",
    "\n",
    "* **Lớp 13: Flatten**\n",
    "    * Chuyển ma trận 4x4x128 về vector 1 chiều\n",
    "    * Đầu ra: 4x4x128 = 2048 chiều\n",
    "\n",
    "* **Lớp 14: Fully Connected**\n",
    "    * Số neuron: 256\n",
    "    * Hàm kích hoạt: ReLU\n",
    "    * Đầu vào: 2048\n",
    "    * Đầu ra: 256\n",
    "\n",
    "* **Lớp 15: Dropout**\n",
    "    * Tỉ lệ dropout: 0.5( tắt ngẫu nhiên 50% neuron trong quá trình huấn luyện)\n",
    "    * Đầu ra 256\n",
    "\n",
    "* **Lớp 16: Fully Connected( Lớp đầu ra)**\n",
    "    * Số neuron: 1\n",
    "    * Hàm kích hoạt: Sigmoid\n",
    "    * Đầu vào: 256\n",
    "    * Đầu ra: 1( xác suất ảnh lả real/ fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92021b5a",
   "metadata": {},
   "source": [
    "### **3. Xây dựng mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6262b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\hung\\project2\\myvenv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de943990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thư viện\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Định nghĩa lớp mô hình, lớp mô hình phải được kế thừa từ lớp cha nn.Module\n",
    "class LivenessNet( nn.Module ):\n",
    "    \n",
    "    # Xây dựng phương thức khởi tạo\n",
    "    # Trong phương thức khởi tạo thì xây dựng kiến trúc mạng\n",
    "    def __init__(self):\n",
    "        # Gọi phương thức khởi tạo của lớp cha\n",
    "        super(LivenessNet, self).__init__()\n",
    "\n",
    "        # Xây dựng kiến trúc mạng\n",
    "        self.network = nn.Sequential(\n",
    "            # Đầu vào 64x64x3\n",
    "            nn.Conv2d(\n",
    "                in_channels=3, \n",
    "                out_channels=32, \n",
    "                kernel_size=3,\n",
    "                padding=\"same\"\n",
    "                ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # đầu ra 64x64x32\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "            ),\n",
    "            # đầu ra là 32x32x32\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # đầu ra là 32x32x64\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            ),\n",
    "            # đầu ra là 16x16x64\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # đầu ra 16x16x128\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            ),\n",
    "            #đầu ra 8x8x128\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                padding=\"same\"\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            #đầu ra 8x8x128\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=2,\n",
    "                stride=2\n",
    "            ),\n",
    "            # đầu ra 4x4x128\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=2048,\n",
    "                out_features=256,\n",
    "            ),\n",
    "            # đầu ra 256\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(\n",
    "                in_features=256,\n",
    "                out_features=2\n",
    "            ),\n",
    "            nn.Sigmoid()   \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e378e1",
   "metadata": {},
   "source": [
    "## **Huấn luyện mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5419dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in e:\\hung\\project2\\myvenv\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.7.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch==2.7.0->torchvision) (4.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch==2.7.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in e:\\hung\\project2\\myvenv\\lib\\site-packages (from torch==2.7.0->torchvision) (78.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801afadb",
   "metadata": {},
   "source": [
    "### **Nạp dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1733e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "# Đường dẫn đến thư mục gốc của thư mục chứa data\n",
    "data_path = os.path.join(\"..\",\"Data\",\"Dataset\")\n",
    "# Định nghĩa hàm resize ảnh\n",
    "transformImage = transforms.Compose(\n",
    "    [transforms.Resize((64, 64)), transforms.ToTensor()]\n",
    "    )\n",
    "# Load data \n",
    "dataset = ImageFolder(root = data_path, transform=transformImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "445a880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6894"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9ac96",
   "metadata": {},
   "source": [
    "### **Chia tập train, test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc695f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\hung\\project2\\myvenv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69dc9a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  4825\n",
      "test:  2069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Tạo danh sách các chỉ số của tập dataset gốc\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "# Lấy danh sách các nhãn của tập dataset\n",
    "labels = [dataset[i][1] for i in indices]\n",
    "\n",
    "# Chia tập train, test, tỉ lệ các mẫu trong mỗi tập train, test sẽ tương tự nhau\n",
    "train_idx, test_idx = train_test_split(indices,test_size= 0.3, random_state = 42, stratify= labels )\n",
    "\n",
    "# Tạo các đối tượng Subset từ tập chỉ số train, và test vừa lấy được\n",
    "trainDataset = Subset(dataset, train_idx)\n",
    "testDataset = Subset(dataset, test_idx)\n",
    "\n",
    "print(\"train: \", len(trainDataset))\n",
    "print(\"test: \", len(testDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80a969",
   "metadata": {},
   "source": [
    "### **Tạo batch các dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7791629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataLoader = DataLoader(trainDataset, 16, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de269bb",
   "metadata": {},
   "source": [
    "### **Huấn luyện**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1af54",
   "metadata": {},
   "source": [
    "#### **Chọn các thành phần huấn luyện**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9e7fa4",
   "metadata": {},
   "source": [
    "* Khởi tạo mô hình\n",
    "\n",
    "* Hàm loss: *Cross Entropy* ( phù hợp với phân loại nhị phân)\n",
    "\n",
    "* Chiến lược cập nhật trọng số: *Adam* ( phổ biến)\n",
    "    * `lr`: tốc độ học : *0.001*\n",
    "\n",
    "* Số epochs huấn luyện: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88e19f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optimize\n",
    "\n",
    "model = LivenessNet()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "optimizer = optimize.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae0d41",
   "metadata": {},
   "source": [
    "### **Định nghĩa hàm train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_function, epochs, optimizer, dataloader):\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        print(\"Epoch: \", i)\n",
    "        for image, label in dataloader:\n",
    "            # Feedforward\n",
    "            output = model(image)\n",
    "            # Tính toán hàm mất mát\n",
    "            loss = loss_function(output, label)\n",
    "            # Lan truyền gradient\n",
    "            # Xóa gradient về 0\n",
    "            optimizer.zero_grad()\n",
    "            # Lan truyền gradient\n",
    "            loss.backward()\n",
    "            # Cập nhật trọng số\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d435b54",
   "metadata": {},
   "source": [
    "### **Thực hiện huấn luyện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cda2b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_function, epochs, optimizer, dataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34dd83",
   "metadata": {},
   "source": [
    "## **Lưu mô hình**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9667c74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu thành công\n"
     ]
    }
   ],
   "source": [
    "path = \"checkpoint.pth\"\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    path\n",
    ")\n",
    "print(\"Lưu thành công\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b580f9b",
   "metadata": {},
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b0d6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,image):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predict = torch.argmax(output, dim = 1)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "692221fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647172689437866"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(model, testDataset):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    dataLoader = DataLoader(testDataset, batch_size=64, shuffle = False)\n",
    "    \n",
    "    trueLabel = 0\n",
    "    totalSample = len(testDataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in dataLoader:\n",
    "            # Di chuyển các mẫu lên thiết bị tính toán( là GPU nếu GPU sẵn sàng, không thì là CPU)\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            predictOutput = predict(model, image)\n",
    "\n",
    "            number_true_label = torch.sum(predictOutput == label)\n",
    "            trueLabel +=  number_true_label\n",
    "    return (trueLabel/totalSample).item()\n",
    "accuracy(model,testDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f693337",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project2Env",
   "language": "python",
   "name": "project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
